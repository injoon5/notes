
주제: 인공지능에 규제가 필요한가.

의견: 필요하다

- 인공지능 원리 다른 어느 알고리즘과 다르다! 그냥 보기에는 비효율적으로 보이는데.. 딥러닝에 집중 → 생명체의 뇌 구조를 모방해서 만들었지만, 우리가 세상을 이해하는 것과는 사뭇 다르다 (가중치 곱하는 등 수학적인 연산) 최근 ChatGPT 등 LLM도 그저 다음 단어로 나올 것 같은 확률이 가장 큰 단어들을 이어 붙이는 것 **따라서 이들이 세상을 제대로 ‘이해’ 한다고 할 수 없다**

[What Is Machine Learning, and How Does It Work? Here's a Short Video Primer](https://www.scientificamerican.com/video/what-is-machine-learning-and-how-does-it-work-heres-a-short-video-primer/)



- 도입
- 긍정적 사례
- 부정적 사례 -> 꼭 좋은 것만은 아님, 막으려면 규제가 필요함
- 사용자 측면/개발자 측면 규제로 나누기 (사용, 데이터)
- 인공지능 원리 / 특성 (윤리적인 판단 불가, 단어 짜맞추기)
- 결론

- 참고문헌


저는 인공지능의 기술 발전보다 관련 규제를 마련하는 것이 우선되어야 한다고 생각합니다. 

2016년 알파고의 바둑 대국 이후 대중에게 널리 알려진 인공지능 기술이 2022년 12월 ChatGPT의 출시로 더욱 주목을 받고 있다. 인공지능 기술의 빠른 발전 덕분에 이제는 인공지능이 우리 생활 곳곳에서 흔히 보이고, 또 관련 소식도 많이 들려오고 있다.

인공지능을 활용한 사례로는 첫 번째, 시각 장애인들의 보조도구로 사용할 수 있게 하는 것이 있다. 시야가 제한된 시각 장애인들이 컴퓨터 비전(시각지능)을 통해 주변 상황을 파악할 수 있게 한다. 두 번째로는, 인공지능을 이용해 식량 생산량, 야생 환경 등 다양한 데이터를 분석해 결과에 맞는 대응을 할 수 있게 하기도 한다. 이 경우에는 인간이 포착하지 못한 특이점이나 규칙 등을 인공지능이 더 잘 포착하여 더욱 효과적인 대응이 가능하게 만들기도 한다.[1]

그러나 최근, 인공지능에 대한 규제가 제대로 마련되어 있지 않다보니 다양한 문제들이 대두되고 있습니다. 첫 번째 사례로는으로는 딥페이크 기술의 악용이 있다. 인간 이미지를 합성하는 기술로, 최근 이를 이용해 유명 연예인, 정치인 등 사회적으로 영향을 크게 끼치는 인물들을 합성해 거짓 사실을 유포하는 경우가 많이 일어나고 있어 사회적인 혼란을 일으키고 있다. 두 번째로는 편향된 데이터 학습으로 인한 불평등 피해가 있다. 2018년 아마존 채용 과정에서 지원자를 가려내는데 사용되었던 인공지능이 기존 컴퓨터/과학 업계에 존재하던 남성 편향 현상을 그대로 학습해 가장 적합한 지원자로 남자 지원자만 골랐다는 것이 밝혀지며 이 인공지능이 사용 중지되었던 사건이 있다. [2] 

이러한 문제들의 원인은 인공지능의 근본적인 특성에 있습니다. 

먼저, 제대로 된 생각을 하지 못한다는 점이 있습니다. 생물의 뇌 구조를 모방하여 만들어졌다고 하지만, 아직 뇌에 대해 자세히 밝혀진 내용이 거의 없어 실제 뇌와는 크게 차이가 나는 구조일 뿐더러, 현재까지의 기술로는 인공지능이 실제로 생각을 하지 못하고 기존의 내용을 짜 맞추기만 할 수 있다. [3] ~~실제로 딥러닝 기술을 기반으로 하여 만들어진 것으로 알려져 있는 LLM(ChatGPT 등)은 생각을 하는 것이 아닌 그저 다음으로 나올 가장 적합한 단어를 고르는 방식으로 작동한다.~~ 실제 생각을 하지 않는다는 점에서 인공지능은 아직까지 인간의 사고를 제대로 모방할 수 없고, ~~구조상 윤리적인 판단을 할 수 없다. 데이터를 보고 단순히 규칙을 찾아 답변을 내는 것이다보니 출력물은 제대로 나오지만, ~~우리가 인간이라면 당연히 거치는 과정들을 밟지 않다 보니 의도치 않게 혐오표현, 인종차별 등 윤리에 어긋나는 출력값을 내놓을 수 있다. 또한, 만약 사용자가 악의적으로 인공지능을 사용하게 된다면 아무 거리낌 없이 문제가 될 만한 실행을 할 수 있다. 

두 번째로, 개발자가 자신이 개발한 인공지능이 어떻게 사용될지를 예상할 수 없다는 문제가 있습니다. 인공지능은 기존의 발명품, 기술들과는 다르게 개발자가 어떠한 용도로 이 인공지능이 사용될 지를 예측하기가 불가능에 가깝다. 실제로 일본에서 다양한 종류의 빵을 구별하려는 의도로 만들어진 인공지능이 암 세포를 찾아내는 용도로도 쓰이는 사례가 있기도 할 정도인데, [4] 만약 사용자가 인공지능을 악의적으로 사용하는것을 막으려고 해도 무엇을 막아야 할 지 정확하게 파악하기가 

마지막으로, 인공지능의 학습 과정에서 발생하는 정보 유출 문제가 있습니다. 인공지능에서 구조 만큼이나 중요한 것은 데이터이다. 같은 코드로 작성된 인공지능이라도, 어떤 데이터를 훈련시키느냐에 따라서 전혀 다른 출력값을 내놓을 수 있다. 최근 출시되는 인공지능 모델들은 대부분 방대한 양의 웹 데이터를 크롤링하여 학습을 진행하는데, 이 과정에서 개인정보 같은 민감한 요소들이 포함된다면 인공지능이 추후 생성물에서 이를 그대로 노출시켜 문제가 생길 수 있다. 실제로 삼성전자에서 자사 코드의 유출을 막고자 사내 ChatGPT 사용을 제한하기도 했다. [5] 이와 더불어 한 번 수집되어 학습된 자료는 삭제하기 어렵다는 문제가 존재하기도 한다. 

이렇게 살펴보았듯, 인공지능에 있어서는 기술 발전보다 규제가 우선시 되어야 한다. 왜냐하면 인공지능도 인간과 똑같이 하나의 지능으로서 취급하여 도덕적/사회적인 규범이 적용되도록 해야만 인간사회에 혼란을 초래하지 않고 인류의 발전을 위해 기여할 수 있게 될 것입니다. 그럼 인공지능이 어떻게 규제되며 사용되어야 하는가. 첫 번째, 데이터 학습 과정이 투명하고 공평하게, 편향이 일어나지 않도록 데이터의 출처까지 투명하게 공개되도록 규제해야 합니다. 두 번째로는 규제에 어긋나게 악의적으로 사용되었을 경우 엄중한 처벌을 내리도록 해야 합니다. 

이렇게 올바른 규제가 마련되었을 때 인공지능도 인류 발전에 도움이 되는 방향으로 발전되어 나갈 것입니다. 


[1]: https://www.forbes.com/sites/bernardmarr/2020/06/22/10-wonderful-examples-of-using-artificial-intelligence-ai-for-good/?sh=19af01112f95
[2]: https://www.ml.cmu.edu/news/news-archive/2016-2020/2018/october/amazon-scraps-secret-artificial-intelligence-recruiting-engine-that-showed-biases-against-women.html

[3]: https://www.forbes.com/sites/danielshapiro1/2019/10/23/can-artificial-intelligence-think/?sh=283fba732d7c
[4]: https://www.newyorker.com/tech/annals-of-technology/the-pastry-ai-that-learned-to-fight-cancer
[5]: https://techcrunch.com/2023/05/02/samsung-bans-use-of-generative-ai-tools-like-chatgpt-after-april-internal-data-leak/